# -*- coding: utf-8 -*-
"""Yield_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ihecw2R6RQijhhKoCHEZ7PT3W7vXys2L
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

crop_data=pd.read_excel("/content/yield_prediction.xlsx")
crop_data

print(crop_data['Crop'].unique())
print(crop_data['Crop'].unique().shape)

crop_data.info()

crop_data.isnull().sum()

crop_data = crop_data.dropna()
crop_data

crop_data.isnull().values.any()

crop_data.State_Name.unique()

crop_data['Yield'] = (crop_data['Production'] / crop_data['Area'])
crop_data.head(10)

sns.barplot(x=crop_data["State_Name"], y=crop_data["Production"])
plt.xticks(rotation = 90)

data = crop_data.drop(['State_Name'], axis = 1)

data.corr(numeric_only=True)

data

dummy = pd.get_dummies(data)
dummy

from sklearn.model_selection import train_test_split

x = dummy.drop(["Crop_Year","Production","Yield"], axis=1)
y = dummy["Production"]
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25, random_state=42)

print("x_train :",x_train.shape)
print("x_test :",x_test.shape)
print("y_train :",y_train.shape)
print("y_test :",y_test.shape)

print(x_train)

print(y_train.isna().sum())

x_train.dropna(inplace=True)
y_train.dropna(inplace=True)

print(x_train[x_train == np.inf].count())
print(y_train[y_train == np.inf].count())

print(x_train[x_train > np.finfo(np.float64).max].count())
print(y_train[y_train > np.finfo(np.float64).max].count())

from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(x_train,y_train)

lr_predict = model.predict(x_test)
lr_predict

model.score(x_test,y_test)

from sklearn.metrics import r2_score
r = r2_score(y_test,lr_predict)
print("R2 score : ",r)

from sklearn.ensemble import RandomForestRegressor
model = RandomForestRegressor(n_estimators = 11)
model.fit(x_train,y_train)
rf_predict = model.predict(x_test)
rf_predict

model.score(x_test,y_test)

from sklearn.metrics import r2_score
r1 = r2_score(y_test,rf_predict)
print("R2 score : ",r1)

ax = sns.distplot(y_test, hist = False, color = "r", label = "Actual value ")
sns.distplot(rf_predict, hist = False, color = "b", label = "Predicted Values", ax = ax)
plt.title('Random Forest Regression')

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.fit_transform(x_test)

print(x_train)
print(x_test)



svr_predict = regressor.predict(x_test)
svr_predict

ax = sns.distplot(y_test, hist = False, color = "r", label = "Actual value ")
sns.distplot(svr_predict, hist = False, color = "b", label = "Predicted Values", ax = ax)
plt.title('Support Vector Regression')

from sklearn.tree import DecisionTreeRegressor
regressor = DecisionTreeRegressor(random_state = 5)
regressor.fit(x_train,y_train)

# Predicting results
decisiontree_predict = regressor.predict(x_test)
decisiontree_predict

regressor.score(x_test,y_test)

from sklearn.metrics import r2_score
r2 = r2_score(y_test,decisiontree_predict)
print("R2 score : ",r2)

Adjr2_2 = 1 - (1-r)*(len(y_test)-1)/(len(y_test)-x_test.shape[1]-1)
print("Adj. R-Squared : {}".format(Adjr2_2))

ax = sns.distplot(y_test, hist = False, color = "r", label = "Actual value ")
sns.distplot(decisiontree_predict, hist = False, color = "b", label = "Predicted Values", ax = ax)
plt.title('Decision Tree Regression')







